import os
import glob
import numpy as np
import random
import time
import base64
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
import google.generativeai as genai
from flask import Flask, request, jsonify
from flask_cors import CORS

# ================================ CONFIG ================================= #
API_KEY = "AIzaSyBBYqOX_7fyedm2Yj8MoN6jBeKbOhUCvPM"
IMAGE_DIR = r"C:\Users\SARA\OneDrive - Manisa Celal Bayar Ãœniversitesi\MasaÃ¼stÃ¼\Pawmate\data\archive (1)\images"
# SÄ±rayla deneyecek model listesi (en hÄ±zlÄ±dan baÅŸlayarak)
MODEL_NAMES = [
    "models/gemini-2.5-flash",           # En hÄ±zlÄ± ve yeni
    "models/gemini-2.0-flash",           # HÄ±zlÄ± alternatif
    "models/gemini-flash-latest",        # Genel alias
]
FEATURE_CACHE_FILE = "feature_cache_64.npy" # Dosya adÄ±nÄ± sabitledim
TEST_SPEED_MODE = False  # ğŸ”¥ TÃ¼m gÃ¶rselleri kullan (en doÄŸru)
TEST_SAMPLE_SIZE = 200   # Speed mode aÃ§Ä±ksa kullanÄ±lÄ±r
TEST_FEATURE_SIZE = 64
# =========================================================================== #

print("\nğŸ”§ BaÅŸlatÄ±lÄ±yor...\n")

# ============================= GEMINI CONFIG ============================== #
llm_available = False
working_model = None

if API_KEY:
    try:
        genai.configure(api_key=API_KEY)
        
        # Her modeli sÄ±rayla dene
        for model_name in MODEL_NAMES:
            try:
                test_model = genai.GenerativeModel(model_name)
                # Basit bir test
                # test_response = test_model.generate_content("Hi") # HÄ±z iÃ§in yorum satÄ±rÄ±
                working_model = model_name
                print(f"ğŸ”‘ Gemini API hazÄ±r | Model: {model_name}")
                llm_available = True
                break
            except Exception as e:
                continue
        
        if not llm_available:
            print("âš  HiÃ§bir Gemini modeli Ã§alÄ±ÅŸmadÄ±")
            
    except Exception as e:
        print(f"âš  Gemini API kullanÄ±lamÄ±yor: {e}")
        llm_available = False
else:
    print("âš  API_KEY tanÄ±mlÄ± deÄŸil â†’ Sadece CNN modu")

# ============================= DATASET LOAD =============================== #
print(f"ğŸ“‚ Dataset klasÃ¶rÃ¼: {IMAGE_DIR}")
jpg_files = []
if os.path.exists(IMAGE_DIR):
    jpg_files = glob.glob(os.path.join(IMAGE_DIR, "*.jpg"))
    print(f"ğŸ¾ Toplam gÃ¶rsel: {len(jpg_files)}")
else:
    print("âŒ GÃ¶rsel klasÃ¶rÃ¼ bulunamadÄ±!")

# ============================= MAGNITUDE: Cat/KÃ¶pek AyrÄ±mÄ± ================= #
cat_breeds = ["Abyssinian", "Bengal", "Birman", "Bombay", "British_Shorthair", "Egyptian_Mau",
              "Maine_Coon", "Persian", "Ragdoll", "Russian_Blue", "Siamese", "Sphynx"]

# ============================= CNN MODEL LOAD ============================ #
print("\nğŸ“¦ MobileNetV2 yÃ¼kleniyor...")
feature_model = MobileNetV2(weights="imagenet", include_top=False, pooling="avg")
print("âœ” CNN model hazÄ±r.\n")

# ============================= FEATURE EXTRACTION ========================= #
def extract_features(img_path):
    try:
        img = image.load_img(img_path, target_size=(224, 224))
        x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))
        features = feature_model.predict(x, verbose=0)[0]
        # ğŸ”¥ TEST_FEATURE_SIZE kadar feature al
        return features[:TEST_FEATURE_SIZE] if TEST_FEATURE_SIZE < len(features) else features
    except Exception as e:
        print(f"Feature hatasÄ± ({img_path}): {e}")
        return np.zeros(TEST_FEATURE_SIZE)

# ============================= FEATURE CACHE ============================= #
# BurasÄ± senin orijinal kodundaki cache oluÅŸturma mantÄ±ÄŸÄ±
print(f"\nğŸ’¾ Cache kontrol ediliyor... ({FEATURE_CACHE_FILE})")

if os.path.exists(FEATURE_CACHE_FILE):
    feature_db = np.load(FEATURE_CACHE_FILE, allow_pickle=True).item()
    print(f"âš¡ Cache yÃ¼klendi ({len(feature_db)} kayÄ±t)")
else:
    print(f"ğŸ›  Cache oluÅŸturuluyor ({TEST_FEATURE_SIZE} feature)...")
    print("   Ä°lk Ã§alÄ±ÅŸtÄ±rma dataset bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re sÃ¼rebilir...")
    feature_db = {}
    if jpg_files:
        for i, path in enumerate(jpg_files):
            if i % 100 == 0:
                print(f"   Ä°ÅŸlenen: {i}/{len(jpg_files)}")
            feature_db[path] = extract_features(path)
        np.save(FEATURE_CACHE_FILE, feature_db)
        print("âœ” Cache oluÅŸturuldu.")
    else:
        print("âš  Dataset boÅŸ olduÄŸu iÃ§in cache oluÅŸturulamadÄ±.")

# ============================= PROMPT FONKSÄ°YONU ========================== #
def build_prompt(breed, is_cat, user_data):
    animal_type = "kedi" if is_cat else "kÃ¶pek"
    owner = user_data.get('ownerName', 'KullanÄ±cÄ±')
    living = user_data.get('living', 'bilinmiyor')
    
    return f"""
    Sen bir veteriner uzmanÄ±sÄ±n.
    Tespit edilen hayvan: **{animal_type}** ({breed})
    Sahip: {owner}, YaÅŸam AlanÄ±: {living}

    LÃ¼tfen ÅŸunlarÄ± saÄŸla (TÃ¼rkÃ§e):
    1. Irk hakkÄ±nda kÄ±sa Ã¶zet
    2. Sahibinin yaÅŸam alanÄ±na ({living}) uygunluk durumu
    3. BakÄ±m Ã¶nerisi
    
    Ton: samimi | uzman.
    """.strip()

# ============================= TAHMÄ°N FONKSÄ°YONU ========================== #
def predict_breed_process(temp_img_path, user_data):
    # 1. Gelen resmin Ã¶zelliklerini Ã§Ä±kar
    target_features = extract_features(temp_img_path)
    
    search_set = list(feature_db.keys())
    # Speed mode kontrolÃ¼ (Senin orijinal kodundan)
    if TEST_SPEED_MODE:
         search_set = random.sample(search_set, min(TEST_SAMPLE_SIZE, len(search_set)))

    best_breed = "Bilinmiyor"
    min_dist = float('inf')
    
    if not search_set:
        return "Bilinmiyor", 0.0, False, "Dataset verisi yok."

    for img_path in search_set:
        db_features = feature_db[img_path]
        dist = np.linalg.norm(target_features - db_features)
        if dist < min_dist:
            min_dist = dist
            best_breed = os.path.basename(img_path).rsplit("_", 1)[0]

    confidence = max(0.01, 1 - min_dist / 12)
    is_cat = best_breed in cat_breeds
    
    advice = "Yapay zeka Ã¶nerisi hazÄ±rlanamadÄ±."
    
    # LLM Tahmin
    if llm_available and working_model:
        try:
            model = genai.GenerativeModel(working_model)
            response = model.generate_content(build_prompt(best_breed, is_cat, user_data))
            advice = response.text
        except Exception as e:
            advice = f"LLM hatasÄ±: {str(e)}"
            
    return best_breed, confidence, is_cat, advice

# ============================= FLASK API ================================== #
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

@app.route('/', methods=['GET'])
def home():
    return "<h1>Pawmates Backend Ã‡alÄ±ÅŸÄ±yor! ğŸš€</h1>"

@app.route('/api/analyze', methods=['POST'])
def analyze():
    # BURADA GÄ°RÄ°NTÄ°LERÄ° DÃœZELTTÄ°M ğŸ‘‡
    try:
        data = request.json
        image_data = data.get('image')
        user_data = data.get('userData', {})

        if not image_data:
            return jsonify({"error": "Resim verisi bulunamadÄ±"}), 400

        if "base64," in image_data:
            image_data = image_data.split(",")[1]

        temp_filename = "temp_upload.jpg"
        with open(temp_filename, "wb") as fh:
            fh.write(base64.b64decode(image_data))

        breed, confidence, is_cat, advice = predict_breed_process(temp_filename, user_data)

        if os.path.exists(temp_filename):
            os.remove(temp_filename)

        return jsonify({
            "breed": breed,
            "confidence": float(confidence),
            "animalType": "cat" if is_cat else "dog",
            "advice": advice
        })

    except Exception as e:
        print("HATA:", e)
        return jsonify({"error": str(e)}), 500

# ğŸ‘‡ EN Ã–NEMLÄ° EKSÄ°K PARÃ‡A BUYDU ğŸ‘‡
if __name__ == "__main__":
    print("\nğŸš€ Sunucu hazÄ±r: http://0.0.0.0:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)